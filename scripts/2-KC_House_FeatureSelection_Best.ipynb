{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c58e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ðŸ“¦ Import Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import RFE, mutual_info_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from scipy import stats\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# ðŸ“¥ Load Dataset & Cleaning\n",
    "df = pd.read_csv(\"/content/kc_house_data.csv\")\n",
    "df = df.drop_duplicates()\n",
    "df = df[(df['bedrooms'] > 0) & (df['bathrooms'] > 0)]\n",
    "df = df.drop(columns=['id', 'date'])\n",
    "\n",
    "# ðŸŽ¯ Features and Target\n",
    "X = df.drop(columns='price')\n",
    "y = df['price']\n",
    "\n",
    "# ðŸ”¢ Numerical Features\n",
    "num_features = X.select_dtypes(include=np.number).columns.tolist()\n",
    "print(\"Numerical features:\", num_features)\n",
    "\n",
    "# ðŸ§  Categorical Features\n",
    "cat_features = X.select_dtypes(include='object').columns.tolist()\n",
    "print(\"Categorical features:\", cat_features)\n",
    "\n",
    "# ðŸ“ˆ Check Normality\n",
    "print(\"\\n--- Checking Normality of Numerical Features ---\")\n",
    "for col in num_features:\n",
    "    plt.figure(figsize=(6,3))\n",
    "    sns.histplot(X[col], kde=True)\n",
    "    plt.title(f\"Distribution of {col}\")\n",
    "    plt.show()\n",
    "    \n",
    "    k2, p = stats.normaltest(X[col])\n",
    "    print(f\"{col}: p = {p:.3f} => {'Non-normal' if p < 0.05 else 'Normal'}\")\n",
    "\n",
    "print(\"\\nâœ… Numeric Features Conclusion: Most are not normally distributed (right-skewed)\")\n",
    "\n",
    "# ðŸ“Š Correlation with Price\n",
    "corr_matrix = df.corr()\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(corr_matrix[['price']].sort_values(by='price', ascending=False), annot=True, cmap='coolwarm')\n",
    "plt.title(\"Correlation with Price\")\n",
    "plt.show()\n",
    "\n",
    "# ðŸŒ² Feature Importance with Random Forest\n",
    "model_rf = RandomForestRegressor(random_state=42)\n",
    "model_rf.fit(X, y)\n",
    "rf_importances = pd.Series(model_rf.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "rf_importances.plot(kind='bar')\n",
    "plt.title(\"Feature Importances from Random Forest\")\n",
    "plt.show()\n",
    "\n",
    "# ðŸŒ³ Decision Tree Feature Importance\n",
    "dtree = DecisionTreeRegressor(random_state=0)\n",
    "dtree.fit(X[num_features], y)\n",
    "dt_importances = pd.Series(dtree.feature_importances_, index=num_features).sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "dt_importances.plot(kind='bar')\n",
    "plt.title(\"Decision Tree Feature Importances\")\n",
    "plt.show()\n",
    "\n",
    "# ðŸ” Recursive Feature Elimination (RFE)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "estimator = LinearRegression()\n",
    "selector = RFE(estimator, n_features_to_select=10)\n",
    "selector = selector.fit(X_scaled, y)\n",
    "\n",
    "rfe_features = pd.Series(selector.support_, index=X.columns)\n",
    "selected_rfe = rfe_features[rfe_features == True].index.tolist()\n",
    "\n",
    "print(\"\\nâœ… Selected features by RFE:\")\n",
    "print(selected_rfe)\n",
    "\n",
    "# ðŸ§  Mutual Information - Categorical\n",
    "if cat_features:\n",
    "    X_encoded = pd.get_dummies(X[cat_features], drop_first=True)\n",
    "    mi_cat = mutual_info_regression(X_encoded, y)\n",
    "    mi_cat_series = pd.Series(mi_cat, index=X_encoded.columns).sort_values(ascending=False)\n",
    "\n",
    "    plt.figure(figsize=(10,5))\n",
    "    mi_cat_series.plot(kind='bar')\n",
    "    plt.title(\"Mutual Information - Categorical Features\")\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\nâœ… Categorical Features Conclusion:\")\n",
    "    print(\"Top categorical features based on mutual information:\")\n",
    "    print(mi_cat_series.head())\n",
    "else:\n",
    "    print(\"\\nNo categorical features found in the dataset.\")\n",
    "\n",
    "# ðŸ”¢ Mutual Information - Numerical\n",
    "mi_num = mutual_info_regression(X[num_features], y)\n",
    "mi_num_series = pd.Series(mi_num, index=num_features).sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "mi_num_series.plot(kind='bar')\n",
    "plt.title(\"Mutual Information - Numerical Features\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… Numerical Features Conclusion:\")\n",
    "print(\"Top numerical features based on mutual information:\")\n",
    "print(mi_num_series.head())\n",
    "\n",
    "# ðŸ“Œ Final Summary\n",
    "print(\"\\nðŸ“Œ Final Feature Selection Summary\")\n",
    "print(\"âœ”ï¸ Top features from Random Forest:\")\n",
    "print(rf_importances.head())\n",
    "print(\"\\nâœ”ï¸ Top features from Decision Tree:\")\n",
    "print(dt_importances.head())\n",
    "print(\"\\nâœ”ï¸ Top features selected by RFE:\")\n",
    "print(selected_rfe)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
